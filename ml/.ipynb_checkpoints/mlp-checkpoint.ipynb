{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312646bb-f7e7-41b2-9132-94ba2f8b0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b790fa00-5855-411d-9ed7-b8261af32aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = open('names.txt','r').read().splitlines()\n",
    "chars = sorted(list(set((''.join(names)))))\n",
    "stoi = {s: i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {stoi[s]: s for s in stoi}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a722e6b9-1094-4046-8859-b4facfc36e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... -> e\n",
      "..e -> m\n",
      ".em -> m\n",
      "emm -> a\n",
      "mma -> .\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "X, y = [], []\n",
    "for name in names[:1]:\n",
    "    context = [0] * block_size\n",
    "    for char in name + '.':\n",
    "        i = stoi[char]\n",
    "        X.append(context)\n",
    "        y.append(i)\n",
    "        print(''.join(itos[j] for j in context), '->', itos[i])\n",
    "        context = context[1:] + [i]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2f44f93-415c-4c55-9cad-03432f9188ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), torch.int64, torch.Size([5]), torch.int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, y.shape, y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1c3ceb98-97cb-4665-a28a-4235f5c2844c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2282c976-72dc-4cb8-b92b-f4de0a008faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4153e-01, -2.8606e-01],\n",
       "        [ 7.1808e-01, -7.7420e-01],\n",
       "        [ 2.0315e-01, -6.5806e-01],\n",
       "        [-3.0334e-01, -1.0675e-01],\n",
       "        [-2.5420e+00, -2.5484e+00],\n",
       "        [-5.1457e-01, -4.0098e-02],\n",
       "        [ 6.2412e-01,  5.2863e-01],\n",
       "        [ 1.2996e+00,  1.0269e+00],\n",
       "        [ 1.1129e+00,  1.4537e+00],\n",
       "        [ 3.9662e-01,  5.3558e-01],\n",
       "        [-8.5622e-01, -1.0989e+00],\n",
       "        [ 3.3679e-01,  3.2025e-01],\n",
       "        [-1.9287e-01,  3.4698e-01],\n",
       "        [-1.5961e-01,  4.1318e-01],\n",
       "        [ 1.4522e+00,  6.7457e-04],\n",
       "        [-1.1808e+00, -1.4254e-01],\n",
       "        [ 1.5959e-01,  2.8027e-01],\n",
       "        [ 2.8801e-01, -1.3377e+00],\n",
       "        [ 2.0733e+00, -1.2552e+00],\n",
       "        [ 3.4556e-01, -2.9449e-01],\n",
       "        [-8.4186e-01, -4.6783e-02],\n",
       "        [-1.6746e-01, -1.8327e-02],\n",
       "        [-6.5582e-01,  9.3355e-01],\n",
       "        [-1.6273e+00,  1.3746e-01],\n",
       "        [-3.5579e-01, -6.2376e-01],\n",
       "        [ 4.1289e-02,  1.5127e-01],\n",
       "        [-1.4480e-02, -4.8493e-01]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embed 27 possible output chars (rows) into 2 dimensional vector space (cols)\n",
    "C = torch.randn(27, 2)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8c6bc-7801-4fa5-a049-b553509cb999",
   "metadata": {},
   "source": [
    "**Indexing instead of one-hot encoding**\n",
    "\n",
    "We could retrieve the embedding of each input by one hot encoding it and then doing `X_onehot @ C`, but it's equivalent to just indexing which is must faster, i.e. `X_onehot = F.one_hot(X); X_onehot @ C == C[X]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e8f6978-0144-4174-835b-d2f7963b0d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2415, -0.2861],\n",
       "         [ 0.2415, -0.2861],\n",
       "         [ 0.2415, -0.2861]],\n",
       "\n",
       "        [[ 0.2415, -0.2861],\n",
       "         [ 0.2415, -0.2861],\n",
       "         [-0.5146, -0.0401]],\n",
       "\n",
       "        [[ 0.2415, -0.2861],\n",
       "         [-0.5146, -0.0401],\n",
       "         [-0.1596,  0.4132]],\n",
       "\n",
       "        [[-0.5146, -0.0401],\n",
       "         [-0.1596,  0.4132],\n",
       "         [-0.1596,  0.4132]],\n",
       "\n",
       "        [[-0.1596,  0.4132],\n",
       "         [-0.1596,  0.4132],\n",
       "         [ 0.7181, -0.7742]]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bede3f03-db59-409c-a5a2-a2c412d7b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
