{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f35feb1",
   "metadata": {},
   "source": [
    "linear model and least squares\n",
    "\n",
    "\n",
    "residual sum of squares (RSS)\n",
    "\n",
    "\n",
    "obtaining \\Beta by minimising RSS\n",
    "\n",
    "\n",
    "samples from 10 low-variance bivariate gaussians, means normally distributed\n",
    "\n",
    "\n",
    "average of k nearest neighbours\n",
    "\n",
    "\n",
    "error in train and test set against degress of freedom for knn and linear regression\n",
    "\n",
    "\n",
    "expected prediction error (EPE) based on joint distribution of X and Y\n",
    "\n",
    "\n",
    "have many (X,Y) samples and use frequency to get joint distribution\n",
    "\n",
    "\n",
    "get function relating X and Y by minimising EPE pointwise\n",
    "\n",
    "\n",
    "knn does the minimisation directly\n",
    "\n",
    "\n",
    "linear regression assumes underlying model is linear & \"pools\" (X,Y) samples to get model parameters\n",
    "\n",
    "\n",
    "knn fails in higher dimensions because not enough sample points per neighbourhood\n",
    "\n",
    "\n",
    "to capture volume fraction r, need hypercube of edge length r^{1/p}, p is dimension\n",
    "\n",
    "\n",
    "plot of edge length needed to capture fraction r against r for p = 1, ..., 10\n",
    "\n",
    "\n",
    "consider true function Y = exp( -8 * abs(X) ), X \\belongsto R^p\n",
    "\n",
    "\n",
    "take 1000 uniform samples of X and plug into Y to get 1000 (X,Y) samples\n",
    "\n",
    "\n",
    "train knn using samples\n",
    "\n",
    "\n",
    "plug x = x0 = 0 into trained knn model to get y0\n",
    "\n",
    "\n",
    "take 1000 samples many times to compute mean squared error (MSE)\n",
    "\n",
    "\n",
    "MSE = E( (f(x0) - y0)^2 ) = V(y0) + B(y0)^2, B(y0) = ( E(y0) - f(x0) )\n",
    "\n",
    "\n",
    "MSE is an expectation so we need many y0's, hence we take set of 1000 samples many times\n",
    "\n",
    "\n",
    "repeat above for p = 1, ..., 10 to plot MSE against p\n",
    "\n",
    "\n",
    "next derive expression for MSE assuming data follows Y = f(X) + \\epsilon\n",
    "\n",
    "\n",
    "show that MSE grows at a slower rate, but have heavy assumptions about the class of models\n",
    "\n",
    "\n",
    "plot of ratio of linear MSE to knn MSE for f(x) = x1 and f(x) = 0.5 * (x1 + 1)^3\n",
    "\n",
    "\n",
    "goal is function approximation using joint probability distribution\n",
    "\n",
    "\n",
    "maximum likelihood estimation\n",
    "\n",
    "\n",
    "structured regression models: why we need them and what kinds there are\n",
    "\n",
    "\n",
    "bias-variance tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd7fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
